<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Mixture-of-Depths: Dynamically allocating compute in transformer-based language models # Authors: Dativd Raposo(Google DeepMind) and Adam Santoro(Google DeepMind) et.al
“Choice and concentration” is an effective strategies for completing tasks with overall success. It is not necessary to consume same amount of effort and time into all problems. If we expend our energy on trivial issues, we may fail to concentrate on what truly matters. Similary, a technique was introduced that allows languge models to allocate less budget to non-essential tokens instead of focusing equally on all tokens.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/docs/spring24/16_/">
  <meta property="og:site_name" content="Efficient ML Systems">
  <meta property="og:title" content="Efficient ML Systems">
  <meta property="og:description" content="Mixture-of-Depths: Dynamically allocating compute in transformer-based language models # Authors: Dativd Raposo(Google DeepMind) and Adam Santoro(Google DeepMind) et.al
“Choice and concentration” is an effective strategies for completing tasks with overall success. It is not necessary to consume same amount of effort and time into all problems. If we expend our energy on trivial issues, we may fail to concentrate on what truly matters. Similary, a technique was introduced that allows languge models to allocate less budget to non-essential tokens instead of focusing equally on all tokens.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="website">
<title>16 | Efficient ML Systems</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" >
<link rel="canonical" href="http://localhost:1313/docs/spring24/16_/">
<link rel="stylesheet" href="/book.min.309b7ed028807cdb68d8d61e26d609f48369c098dbf5e4d8c0dcf4cdf49feafc.css" integrity="sha256-MJt&#43;0CiAfNto2NYeJtYJ9INpwJjb9eTYwNz0zfSf6vw=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.a4f1e870b1a123bbd9075a3a0ac7cb7ffc0af740da258961ca4eb786cfa38fcb.js" integrity="sha256-pPHocLGhI7vZB1o6CsfLf/wK90DaJYlhyk63hs&#43;jj8s=" crossorigin="anonymous"></script>

  

<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/docs/spring24/16_/index.xml" title="Efficient ML Systems" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>Efficient ML Systems</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8c2bdf4d8f82cc2d8f16541464d61b3d" class="toggle" checked />
    <label for="section-8c2bdf4d8f82cc2d8f16541464d61b3d" class="flex justify-between">
      <a role="button" class="">Spring24</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/00_taco_example/" class="">00 Taco Example</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/01_/" class="">01</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/02_/" class="">02</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/03_/" class="">03</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/04_/" class="">04</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/05_/" class="">05</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/06_/" class="">06</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/07_/" class="">07</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/08_/" class="">08</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/09_/" class="">09</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/10_/" class="">10</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/11_/" class="">11</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/12_/" class="">12</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/13_/" class="">13</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/14_/" class="">14</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/15_/" class="">15</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/16_/" class="active">16</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/17_/" class="">17</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/18_/" class="">18</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/19_/" class="">19</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/20_/" class="">20</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/21_/" class="">21</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/22_/" class="">22</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/23_/" class="">23</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/24_/" class="">24</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/25_/" class="">25</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>16</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#background"><strong>Background</strong></a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#implementing-mixture-of-depth-transformers"><strong>Implementing Mixture-of-Depth Transformers</strong></a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#results--discussion"><strong>Results &amp; Discussion</strong></a></li>
    <li><a href="#references"><strong>References</strong></a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="mixture-of-depths-dynamically-allocating-compute-in-transformer-based-language-models">
  <strong>Mixture-of-Depths: Dynamically allocating compute in transformer-based language models</strong>
  <a class="anchor" href="#mixture-of-depths-dynamically-allocating-compute-in-transformer-based-language-models">#</a>
</h1>
<p><em>Authors: Dativd Raposo(Google DeepMind) and Adam Santoro(Google DeepMind) et.al</em></p>
<p>“Choice and concentration” is an effective strategies for completing tasks with overall success. It is not necessary to consume same amount of effort and time into all problems. If we expend our energy on trivial issues, we may fail to concentrate on what truly matters. Similary, a technique was introduced that allows languge models to allocate less budget to non-essential tokens instead of focusing equally on all tokens.</p>
<p>The tremendous technique developed by Google DeepMind Researchers is called Miture-of-Depths, or MoD for short. In this blog post, we take a look at building blocks of MoD and how they works.</p>
<p>This paper insists that all problems do not require same amount of time to solve in real world and also in language models like Transformer.<br>
But, Transformer models spread FLOPs <strong>&lsquo;uniformly&rsquo;</strong> across input sequences, which is inefficient!<br>
Therefore there are many efforts like &ldquo;early exiting&rdquo; to reduce total FLOPs &amp; <strong>&lsquo;dynamically&rsquo;</strong> allocate compute budgets.<br>
However, these methods do not work well due to hardware constraints.<br>
So, the methods should be sophistically addressed like harmonious with current hardware stack &amp; known tensor sizes that are selected to maximize hardware utilization.</p>
<p align="center">
    <img src=./Mixture-of-Depths.png> 
</p>
<p align="center">
    (Fig 1. Description of overall MoD & comparison between Vanilla Transformer & Early Exit method)
</p>
<p>Therefore, the things that authors of this paper contributed in this paper are listed as follows:</p>
<ol>
<li>Suggestion of method(Mixture-of-Depths, MoD) which limits the total FLOPs by choosing only k tokens which process into Attention + mlp layer.</li>
<li>Comparing this method with vanilla Transformer(isoFLOP) &amp;  Mixture-of-Experts(MoE) &amp; Combined version of MoE + MoD = MoDE</li>
<li>With this method, MoD achieves better performance than vanilla Transformer in isoFLOPs &amp; faster inference speed.</li>
</ol>
<h2 id="background">
  <strong>Background</strong>
  <a class="anchor" href="#background">#</a>
</h2>
<h4 id="early-exit-method">
  Early Exit method
  <a class="anchor" href="#early-exit-method">#</a>
</h4>
<p align="center">
    <img src=./earlyexit.png> 
</p>
<p align="center">
    (Fig 2. Early Exit method)
</p>
<p>Early Exit method is a method when the model decides to end computation on a given token, then model skips the remaining layers.<br>
Difference between MoD is, MoD can choose whether skip middle layer or not, but Early Exit method can&rsquo;t.</p>
<h4 id="what-is-moe">
  What is MoE?
  <a class="anchor" href="#what-is-moe">#</a>
</h4>
<p align="center">
    <img src=./moe.png> 
</p>
<p align="center">
    (Fig 3. Diagram of MoE)
</p>
<p>MoE is an model which consists of parallel expert models which is fitted to certain domains.<br>
Like MoD, token-level routing decisions are made across the network depth.<br>
Difference between MoD is, MoD chooses path to transformer or to residual connection, MoE chooses path to transformer(Expert) or to transformer(Expert) or both.</p>
<h2 id="implementing-mixture-of-depth-transformers">
  <strong>Implementing Mixture-of-Depth Transformers</strong>
  <a class="anchor" href="#implementing-mixture-of-depth-transformers">#</a>
</h2>
<p>High-level strategy of Mixture-of-Depths is as follows:</p>
<h4 id="defining-a-compute-budget">
  <strong>Defining a compute budget</strong>
  <a class="anchor" href="#defining-a-compute-budget">#</a>
</h4>
<ul>
<li>First, to make smaller compute budget per forward pass than vanila transformer, we limit the number of tokens in a sequence for computations like self-attention and MLP. This concept, called <strong>capacity</strong>, defines the total tokens processed and determines the FLOPs required.</li>
<li>For example, in vanila transformers, capacity($T$) covers all tokens, but in MoE transformers, it&rsquo;s dividing among multiple experts.</li>
<li>Lowering computation capacity can reduce the compute budget per forward pass without performance loss if the model learns to prioritize important tokens.</li>
</ul>
<h4 id="routing-around-transformer-blocks">
  <strong>Routing around transformer blocks</strong>
  <a class="anchor" href="#routing-around-transformer-blocks">#</a>
</h4>
<h4 id="routing-schemes">
  <strong>Routing schemes</strong>
  <a class="anchor" href="#routing-schemes">#</a>
</h4>
<h4 id="routing-implementation">
  <strong>Routing implementation</strong>
  <a class="anchor" href="#routing-implementation">#</a>
</h4>
<h4 id="sampling">
  <strong>Sampling</strong>
  <a class="anchor" href="#sampling">#</a>
</h4>
<h2 id="results--discussion">
  <strong>Results &amp; Discussion</strong>
  <a class="anchor" href="#results--discussion">#</a>
</h2>
<h2 id="references">
  <strong>References</strong>
  <a class="anchor" href="#references">#</a>
</h2>
<p>Fig 2. <a href="https://www.sciencedirect.com/science/article/pii/S0893608022002532">https://www.sciencedirect.com/science/article/pii/S0893608022002532</a><br>
Fig 3. <a href="https://deepgram.com/learn/mixture-of-experts-ml-model-guide">https://deepgram.com/learn/mixture-of-experts-ml-model-guide</a></p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">


  <div><a class="flex align-center" href="https://github.com/effml-postech/blog-post/commit/80235bfdda3b5ce0b1eedf3f3ee79f823d375863" title='Last modified by effml-postech | May 20, 2024' target="_blank" rel="noopener">
      <img src="/svg/calendar.svg" class="book-icon" alt="" />
      <span>May 20, 2024</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/effml-postech/blog-post/edit/main//content/docs/spring24/16_/_index.md" target="_blank" rel="noopener">
      <img src="/svg/edit.svg" class="book-icon" alt="" />
      <span>Edit this page</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#background"><strong>Background</strong></a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#implementing-mixture-of-depth-transformers"><strong>Implementing Mixture-of-Depth Transformers</strong></a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#results--discussion"><strong>Results &amp; Discussion</strong></a></li>
    <li><a href="#references"><strong>References</strong></a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












