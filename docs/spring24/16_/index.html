<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Accelerating Transformers via Conditional Computation: As Aspect of Mixture of Depths # Posted by: Inkwan Hwang, Minjae Park
This image was generated by DALL·E 3. Introduction # “Choice and concentration” is an effective strategies for achieving success in problems. Sometimes, it is not necessary to consume same amount of effort and time into all problems. Expending energy on trivial issues may fail to concentrate on what truly matters. Similarly, in language models, there is a technique that does not focus equally on all tokens but allocates less budget to non-essential tokens.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/docs/spring24/16_/">
  <meta property="og:site_name" content="Efficient ML Systems">
  <meta property="og:title" content="Efficient ML Systems">
  <meta property="og:description" content="Accelerating Transformers via Conditional Computation: As Aspect of Mixture of Depths # Posted by: Inkwan Hwang, Minjae Park
This image was generated by DALL·E 3. Introduction # “Choice and concentration” is an effective strategies for achieving success in problems. Sometimes, it is not necessary to consume same amount of effort and time into all problems. Expending energy on trivial issues may fail to concentrate on what truly matters. Similarly, in language models, there is a technique that does not focus equally on all tokens but allocates less budget to non-essential tokens.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="website">
<title>16 | Efficient ML Systems</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" >
<link rel="canonical" href="http://localhost:1313/docs/spring24/16_/">
<link rel="stylesheet" href="/book.min.309b7ed028807cdb68d8d61e26d609f48369c098dbf5e4d8c0dcf4cdf49feafc.css" integrity="sha256-MJt&#43;0CiAfNto2NYeJtYJ9INpwJjb9eTYwNz0zfSf6vw=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.e42e2ea2f0d175e58cc27d52583d6af9c3a7e0fd65c0b17b2665b054ed2a5a20.js" integrity="sha256-5C4uovDRdeWMwn1SWD1q&#43;cOn4P1lwLF7JmWwVO0qWiA=" crossorigin="anonymous"></script>

  

<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/docs/spring24/16_/index.xml" title="Efficient ML Systems" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>Efficient ML Systems</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8c2bdf4d8f82cc2d8f16541464d61b3d" class="toggle" checked />
    <label for="section-8c2bdf4d8f82cc2d8f16541464d61b3d" class="flex justify-between">
      <a role="button" class="">Spring24</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/00_taco_example/" class="">00 Taco Example</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/01_/" class="">01</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/02_/" class="">02</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/03_/" class="">03</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/04_/" class="">04</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/05_/" class="">05</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/06_/" class="">06</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/07_/" class="">07</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/08_/" class="">08</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/09_/" class="">09</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/10_/" class="">10</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/11_/" class="">11</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/12_/" class="">12</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/13_/" class="">13</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/14_/" class="">14</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/15_/" class="">15</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/16_/" class="active">16</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/17_/" class="">17</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/18_/" class="">18</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/19_/" class="">19</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/20_/" class="">20</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/21_/" class="">21</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/22_/" class="">22</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/23_/" class="">23</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/24_/" class="">24</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/25_/" class="">25</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>16</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#introduction"><strong>Introduction</strong></a></li>
    <li><a href="#understanding-the-problem-uniform-computation-in-transformers"><strong>Understanding the problem: Uniform computation in Transformers</strong></a></li>
    <li><a href="#conditional-computation-for-transformers"><strong>Conditional computation for Transformers</strong></a></li>
    <li><a href="#overview-to-mixture-of-depths-mod"><strong>Overview to Mixture-of-Depths (MoD)</strong></a></li>
    <li><a href="#routing-schemes"><strong>Routing schemes</strong></a>
      <ul>
        <li><a href="#token-choice-routing"><strong>Token-choice routing</strong></a></li>
        <li><a href="#expert-choice-routing"><strong>Expert-choice routing</strong></a></li>
        <li><a href="#expert-choice-mod"><strong>Expert-choice MoD</strong></a></li>
      </ul>
    </li>
    <li><a href="#implementation"><strong>Implementation</strong></a></li>
    <li><a href="#more-details"><strong>More details</strong></a>
      <ul>
        <li><a href="#capacity"><strong>Capacity</strong></a></li>
        <li><a href="#autoregressively-sampling"><strong>Autoregressively sampling</strong></a></li>
      </ul>
    </li>
    <li><a href="#open-source-mod-not-official"><strong>Open source MoD</strong> (not official)</a></li>
    <li><a href="#results"><strong>Results</strong></a></li>
    <li><a href="#some-resources"><strong>Some resources</strong></a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="accelerating-transformers-via-conditional-computation-as-aspect-of-mixture-of-depths">
  <strong>Accelerating Transformers via Conditional Computation: As Aspect of Mixture of Depths</strong>
  <a class="anchor" href="#accelerating-transformers-via-conditional-computation-as-aspect-of-mixture-of-depths">#</a>
</h1>
<p><em>Posted by: Inkwan Hwang, Minjae Park</em></p>
<hr>
<p align="center">
    <img src=./Pondering_Transformer.jpg> 
</p>
This image was generated by DALL·E 3.
<h2 id="introduction">
  <strong>Introduction</strong>
  <a class="anchor" href="#introduction">#</a>
</h2>
<p>“Choice and concentration” is an effective strategies for achieving success in problems. Sometimes, it is not necessary to consume same amount of effort and time into all problems. Expending energy on trivial issues may fail to concentrate on what truly matters. Similarly, in language models, there is a technique that does not focus equally on all tokens but allocates less budget to non-essential tokens. This technique is called conditional computation.</p>
<p>In this post, We will explain conditional computation strategies for Transformers, focusing on a technology announced this year called <strong>Mixture-of-Texture.</strong></p>
<p>paper: <U><a href="https://arxiv.org/abs/2404.02258" target="_blank"> Mixture-of-Depths: Dynamically allocating compute in transformer-based language models </a></U></p>
<p>Let&rsquo;s dive in!</p>
<h2 id="understanding-the-problem-uniform-computation-in-transformers">
  <strong>Understanding the problem: Uniform computation in Transformers</strong>
  <a class="anchor" href="#understanding-the-problem-uniform-computation-in-transformers">#</a>
</h2>
<p>These days, most language models are based on Transformers, and we stack these blocks to make big models. When given an input sequence, tokens pass through these blocks to predict the next token. The problem is that the models spread computations uniformly across input sequences. Transformers use the same amount of computation for essential tokens as for non-essential ones. For instance, predicting a token within a sentence is cheaper than predicting the first token of the next sentence. Researchers want to address this issue by making Transformers focus on important tokens by allocating less computing resources.</p>
<h2 id="conditional-computation-for-transformers">
  <strong>Conditional computation for Transformers</strong>
  <a class="anchor" href="#conditional-computation-for-transformers">#</a>
</h2>
<ul>
<li>Early exiting
<p align="center">
  <img src=./Early_Exiting.png> 
</li>
</ul>
</p>
  Instead of passing through all layers, the model can stop early if it is confident enough about its prediction. This saves computation time and resources. Large pre-trained models like BERT can use early exiting ot maintain performance while reducing computational load.
<ul>
<li>
<p>CoLT5</p>
</li>
<li>
<p>Mixture of Experts (MoE)</p>
<p>MoE is an model which consists of parallel expert models which is fitted to certain domains. Like MoD, token-level routing decisions are made across the network depth. Difference between MoD is, MoD chooses path to transformer or to residual connection, MoE chooses path to transformer(Expert) or to transformer(Expert) or both.</p>
</li>
</ul>
<h2 id="overview-to-mixture-of-depths-mod">
  <strong>Overview to Mixture-of-Depths (MoD)</strong>
  <a class="anchor" href="#overview-to-mixture-of-depths-mod">#</a>
</h2>
<p>Self-attention + MLP, Residual Connection 중 고른다는 내용. MoE는 넓이를 줄였지만, MoD는 깊이에 해당한다는 내용.</p>
<p align="center">
    <img src=./Mixture-of-Depths.png> 
</p>
<p>MoE is an model which consists of parallel expert models which is fitted to certain domains.
Like MoD, token-level routing decisions are made across the network depth.
Difference between MoD is, MoD chooses path to transformer or to residual connection, MoE chooses path to transformer(Expert) or to transformer(Expert) or both.</p>
<h2 id="routing-schemes">
  <strong>Routing schemes</strong>
  <a class="anchor" href="#routing-schemes">#</a>
</h2>
<p>Routing implementation is the most crucial part of MoD. The authors compare three routing schemes, demonstrating that MoD is an efficient approach.</p>
<p align="center">
    <img src=./Routing_Schemes.png> 
</p>
<h3 id="token-choice-routing">
  <strong>Token-choice routing</strong>
  <a class="anchor" href="#token-choice-routing">#</a>
</h3>
<p>Token-choice routing is a method where each tokens select the path it will follow. The router produces probability distributions for each token across the computational paths. Based on this distribution, each token chooses its preferred path at each layer.</p>
<p>In token-choice routing, tokens have the flexibility to select their path, allowing for dynamic processing. However, this can lead to path balancing issues as all tokens might preger on the same path. It causes potential overloads on specific paths. To mitigate it, auxility loss is used to ensure that most tokens do not prefer on a single path.</p>
<h3 id="expert-choice-routing">
  <strong>Expert-choice routing</strong>
  <a class="anchor" href="#expert-choice-routing">#</a>
</h3>
<p>Expert-choice routing is the reverse of token-choice routing. Similar to token-choice routing, the router produces a probability distribution for each token. In expert-choice routing, instead of tokens selecting their paths, each path selects the top-k tokwns based on the tokens&rsquo; preferences.</p>
<p>Using this method ensures that each paths receives k tokens, maintauing balance among the paths. However, some tokens may not be selected beacuse there might be common tokens that multiple paths prefer.</p>
<h3 id="expert-choice-mod">
  <strong>Expert-choice MoD</strong>
  <a class="anchor" href="#expert-choice-mod">#</a>
</h3>
<p>This method applies expert-choice routing but uses only a single expert. Since only a single path is utilized, if $k$ is less than the sequence length, not all tokens need to undergo self-attention and MLP computation.</p>
<p>Routing scheme에는 다음과 같은 고려해야할 사항이 있다:</p>
<ul>
<li>연산 효율성
Auxiliary balancing loss가 필요 없다</li>
<li>구현의 단순함
Router의 weight 순서대로 가장 큰 것을 고르면 된다.</li>
<li>명확한 기준
top-k 연산이 router weight의 magnitude에 depend하기 때문에 가장 중요한 토큰이 연산되는 것을 보장할 수 있다.
토큰에게 주어진 경우가 두 가지이므로(slef-attention + MLP, residual connection) top-k는 명확하게 token을 두 set으로 나눌 수 있다.</li>
</ul>
<p>다음과 같은 이유로 저자들은 Expert-choice routing을 사용하기로 하였고, single path만을 사용하기로 하였다.</p>
<h2 id="implementation">
  <strong>Implementation</strong>
  <a class="anchor" href="#implementation">#</a>
</h2>
<p>MoD Transformers는 다음과 같은 방식으로 작동한다.</p>
<ol>
<li>Calculate routing weights

<link rel="stylesheet" href="/katex/katex.min.css" />
<script defer src="/katex/katex.min.js"></script>
<script defer src="/katex/auto-render.min.js" onload="renderMathInElement(document.body);"></script><span>
  \[x^{l&#43;1}_i=\begin{cases}r^{l}_i f_i(\tilde{X}^l)&#43;x^{l}_i, &amp;    \text{if } r^{l}_i &gt;  P_\beta(R^l)\\x^{l}_i, &amp; \text{if }r^{l}_i &lt;  P_\beta(R^l)\end{cases}\]
</span>
</li>
<li>ssss</li>
<li></li>
<li>backward path 및 오차보정</li>
</ol>
<h2 id="more-details">
  <strong>More details</strong>
  <a class="anchor" href="#more-details">#</a>
</h2>
<h3 id="capacity">
  <strong>Capacity</strong>
  <a class="anchor" href="#capacity">#</a>
</h3>
<h3 id="autoregressively-sampling">
  <strong>Autoregressively sampling</strong>
  <a class="anchor" href="#autoregressively-sampling">#</a>
</h3>
<p>The issue with autoregressively sampling is that it lacks information about future tokens, which means it cannot determine whether a token will be in the top-k when it passes through the router. Therefore, to solve this problem, the paper proposes two methods.</p>
<ul>
<li>Simple auxiliary loss
<p align="center">
  <img src=./Routing_Analysis.png> 
</li>
</ul>
</p>
  The first method is introducing an auxiliary loss. By designing an additional binary cross-entropy loss function at the router's output, the value of tokens in the top-$k$ is guided to be greater than 0.5, while the value of tokens are not in the top-$k$ is guided to be less than 0.5. Through its process, when the token passes through the router, it is considered to be in the top-$k$ if its value is higher than 0.5, and it passes through the self-attention and MLP layer. Otherwise, it passses through the residual path. Designing such a function impacts the primary language modeling objective about 0.2-0.3%. We believe this likely refers to the extent to which performance and inference time are affected.
<ul>
<li>
<p>Small auxiliary MLP predictor</p>
<p>The second method does not affect the primary language modeling objective at all. The authors design a new MLP layer that functions as a binary classifier to determine wheather a token is in top-$k$ during the training process. This classifer is trained to make these demterminations, and it is used in real-time during the autoregressive sampling process.</p>
</li>
</ul>
<p>With these methods, authors can sample autoregressively by choosing to route tokens to or around a block based on the router&rsquo;s outer which is not depends on the future tokens. They provide empirical result that auxiliary task achieved 99% accuracy.</p>
<h2 id="open-source-mod-not-official">
  <strong>Open source MoD</strong> (not official)
  <a class="anchor" href="#open-source-mod-not-official">#</a>
</h2>
<p>The followuing is an implementation of MoD that supports various LM such as Mixtral, LLama3 and BLOOM. It implements MoD using PyTorch and Hugging Face Transformers library.</p>
<p>LINK: <a href="https://github.com/astramind-ai/Mixture-of-depths">https://github.com/astramind-ai/Mixture-of-depths</a></p>
<p>The code operates in the following steps:</p>
<ol>
<li>
<p>Token Weight Calculation</p>
<p>The <strong>TokenRouter</strong> module caculates weights for each token based on its embedding. This is done using a lnear layer appleid to the embeddingsm resulting in a weight value for each token.</p>
</li>
<li>
<p>Selective Processing</p>
<p>The processing occurs in the <strong>MoD</strong> module&rsquo;s forward pass</p>
<ul>
<li>First token weights are calculated using <strong>TokenRouter</strong></li>
<li>By a capacity paratmter, the number of tokens are determined. They undergo self-attention and MLP computation.</li>
</ul>
</li>
<li>
<p>Application to Hugging Face Models</p>
<p><strong>apply_mod_to_hf</strong> function applies the MoD mechanism to an existing Hugging Face model.</p>
</li>
</ol>
<p>More detail explanations are HERE. 개인 페이지에 더 자세한 코드 분석 작성.</p>
<h2 id="results">
  <strong>Results</strong>
  <a class="anchor" href="#results">#</a>
</h2>
<p>실험결과</p>
  <p align="center">
    <img src=./result2.png> 
</p>
  <p align="center">
    <img src=./result1.png> 
</p>
## **Conclusion and discussion**
결론 + 내 생각
<h2 id="some-resources">
  <strong>Some resources</strong>
  <a class="anchor" href="#some-resources">#</a>
</h2>
<p>참고문헌 정리</p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">


  <div><a class="flex align-center" href="https://github.com/effml-postech/blog-post/commit/e6084d72bed3522d6793ae37c5d3596a22ab79e8" title='Last modified by Minjae Park | May 22, 2024' target="_blank" rel="noopener">
      <img src="/svg/calendar.svg" class="book-icon" alt="" />
      <span>May 22, 2024</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/effml-postech/blog-post/edit/main//content/docs/spring24/16_/_index.md" target="_blank" rel="noopener">
      <img src="/svg/edit.svg" class="book-icon" alt="" />
      <span>Edit this page</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#introduction"><strong>Introduction</strong></a></li>
    <li><a href="#understanding-the-problem-uniform-computation-in-transformers"><strong>Understanding the problem: Uniform computation in Transformers</strong></a></li>
    <li><a href="#conditional-computation-for-transformers"><strong>Conditional computation for Transformers</strong></a></li>
    <li><a href="#overview-to-mixture-of-depths-mod"><strong>Overview to Mixture-of-Depths (MoD)</strong></a></li>
    <li><a href="#routing-schemes"><strong>Routing schemes</strong></a>
      <ul>
        <li><a href="#token-choice-routing"><strong>Token-choice routing</strong></a></li>
        <li><a href="#expert-choice-routing"><strong>Expert-choice routing</strong></a></li>
        <li><a href="#expert-choice-mod"><strong>Expert-choice MoD</strong></a></li>
      </ul>
    </li>
    <li><a href="#implementation"><strong>Implementation</strong></a></li>
    <li><a href="#more-details"><strong>More details</strong></a>
      <ul>
        <li><a href="#capacity"><strong>Capacity</strong></a></li>
        <li><a href="#autoregressively-sampling"><strong>Autoregressively sampling</strong></a></li>
      </ul>
    </li>
    <li><a href="#open-source-mod-not-official"><strong>Open source MoD</strong> (not official)</a></li>
    <li><a href="#results"><strong>Results</strong></a></li>
    <li><a href="#some-resources"><strong>Some resources</strong></a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












