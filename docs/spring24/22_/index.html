<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Larimar: Large Language Models with Episodic Memory Control # Posted by: Sunggyu Jang, Hyeonwoo Park
Authors: Payel Das (IBM AI Research), Subhajit Chaudhury (IBM AI Research) et.al
1. Background # Large Language Model (LLM) is one of the most famous topics in these days, due to their outstanding performance on various Natural Language Processing (NLP) tasks. However, LLM has faced a lot of challenges at the same time. In this report, we especially focus on the &ldquo;knowledge edit&rdquo; problem.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/docs/spring24/22_/">
  <meta property="og:site_name" content="Efficient ML Systems">
  <meta property="og:title" content="Efficient ML Systems">
  <meta property="og:description" content="Larimar: Large Language Models with Episodic Memory Control # Posted by: Sunggyu Jang, Hyeonwoo Park
Authors: Payel Das (IBM AI Research), Subhajit Chaudhury (IBM AI Research) et.al
1. Background # Large Language Model (LLM) is one of the most famous topics in these days, due to their outstanding performance on various Natural Language Processing (NLP) tasks. However, LLM has faced a lot of challenges at the same time. In this report, we especially focus on the “knowledge edit” problem.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="website">
<title>22 | Efficient ML Systems</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" >
<link rel="canonical" href="http://localhost:1313/docs/spring24/22_/">
<link rel="stylesheet" href="/book.min.309b7ed028807cdb68d8d61e26d609f48369c098dbf5e4d8c0dcf4cdf49feafc.css" integrity="sha256-MJt&#43;0CiAfNto2NYeJtYJ9INpwJjb9eTYwNz0zfSf6vw=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.826402de44b30cc8094d8a635bc5732090913c75bf86d38cfc094dab9e7ccbff.js" integrity="sha256-gmQC3kSzDMgJTYpjW8VzIJCRPHW/htOM/AlNq558y/8=" crossorigin="anonymous"></script>

  

<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/docs/spring24/22_/index.xml" title="Efficient ML Systems" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>Efficient ML Systems</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8c2bdf4d8f82cc2d8f16541464d61b3d" class="toggle" checked />
    <label for="section-8c2bdf4d8f82cc2d8f16541464d61b3d" class="flex justify-between">
      <a role="button" class="">Spring24</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/00_taco_example/" class="">00 Taco Example</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/01_/" class="">01</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/02_/" class="">02</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/03_/" class="">03</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/04_/" class="">04</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/05_/" class="">05</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/06_/" class="">06</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/07_/" class="">07</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/08_/" class="">08</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/09_/" class="">09</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/10_/" class="">10</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/11_/" class="">11</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/12_/" class="">12</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/13_/" class="">13</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/14_/" class="">14</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/15_/" class="">15</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/16_/" class="">16</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/18_/" class="">18</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/19_/" class="">19</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/20_/" class="">20</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/21_/" class="">21</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/22_/" class="active">22</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/23_/" class="">23</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/24_/" class="">24</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/25_/" class="">25</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/17_/" class="">17</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>22</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#1-background">1. Background</a>
      <ul>
        <li><a href="#knowledge-edit-in-llm-research">Knowledge edit in LLM research</a></li>
        <li><a href="#autoencoder">Autoencoder</a></li>
        <li><a href="#memory-network">Memory network</a></li>
        <li><a href="#neocortex-hippocampus-interactions">Neocortex-Hippocampus interactions</a></li>
      </ul>
    </li>
    <li><a href="#2-contributions">2. Contributions</a></li>
    <li><a href="#3-model-architecture">3. Model architecture</a></li>
    <li><a href="#4-memory-operations">4. Memory Operations</a></li>
    <li><a href="#5-results">5. Results</a>
      <ul>
        <li><a href="#wall-clock-time">Wall Clock time</a></li>
        <li><a href="#single-fact-editing">Single Fact Editing</a></li>
        <li><a href="#sequential-fact-editing">Sequential Fact Editing</a></li>
        <li><a href="#selective-forgetting">Selective Forgetting</a></li>
        <li><a href="#recall-performance">Recall Performance</a></li>
      </ul>
    </li>
    <li><a href="#6-conclusion">6. Conclusion</a></li>
    <li><a href="#7-references">7. References</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="larimar-large-language-models-with-episodic-memory-control">
  Larimar: Large Language Models with Episodic Memory Control
  <a class="anchor" href="#larimar-large-language-models-with-episodic-memory-control">#</a>
</h1>
<p><em>Posted by: Sunggyu Jang, Hyeonwoo Park</em></p>
<p><em>Authors: Payel Das (IBM AI Research), Subhajit Chaudhury (IBM AI Research) et.al</em></p>
<h2 id="1-background">
  1. Background
  <a class="anchor" href="#1-background">#</a>
</h2>
<p>Large Language Model (LLM) is one of the most famous topics in these days, due to their outstanding performance on various Natural Language Processing (NLP) tasks. However, LLM has faced a lot of challenges at the same time. In this report, we especially focus on the &ldquo;knowledge edit&rdquo; problem.</p>
<h3 id="knowledge-edit-in-llm-research">
  Knowledge edit in LLM research
  <a class="anchor" href="#knowledge-edit-in-llm-research">#</a>
</h3>
<p>Knowledge edit problem can be summarized as &ldquo;constantly updating the knowledge of pre-trained LLMs to keep models fact-relevant, safe, and ethical after deployment.&rdquo; To be specific, model editing is mandatory to remove the undesired, incorrect, or obsolete facts from the LLM&rsquo;s &ldquo;memory&rdquo;, and optionally replace it with desired outcome. Figures below illustrate why do we need knowledge update.</p>
<p align="center">
    <img src='knowledge update.png' width="600">
</p>
<p align="center">
    (Fig1. Knowledge update: New knowledge should be injected constantly)
</p>
<p align="center">
    <img src='context length generalization.png' width="600">
</p>
<p align="center">
    (Fig2. Context length generalization: The ability to quickly update the LLM can help with "input context length generalization problem")
</p>
<p align="center">
    <img src='selective fact forgetting.png' width="600">
</p>
<p align="center">
    (Fig3. Selective fact forgetting: LLMs should forget personal & sensitive data)
</p>
<h3 id="autoencoder">
  Autoencoder
  <a class="anchor" href="#autoencoder">#</a>
</h3>
<p>TODO : This content can be erased</p>
<p align="center">
    <img src='auto encoder.png' width="600">
</p>
<p align="center">
    (Fig4. Autoencoder)
</p>
<h3 id="memory-network">
  Memory network
  <a class="anchor" href="#memory-network">#</a>
</h3>
<h3 id="neocortex-hippocampus-interactions">
  Neocortex-Hippocampus interactions
  <a class="anchor" href="#neocortex-hippocampus-interactions">#</a>
</h3>
<p>This paper imitates the role of brain. Humans can rapidly update their knowledge after encountering the first relevant instance. In the brain, this process is facilitated through interactions between the neocortex and the hippocampus. The hippocampus is the site for storing long-term memories, while the neocortex integrates long-term and short-term memories to relay the results to the body.</p>
<p align="center">
    <img src=brain.png width="400"> 
</p>
<p align="center">
    (Fig6. Neocortex and the Hippocampus)
</p>
The Complementary Learning Systems (CLS) theory proposes a model that combines these complementary learning systems of the hippocampus and neocortex. The interaction between the neocortex and hippocampus in the brain is known to promote adaptive behavior through memorization and generalization. Furthermore, it is suggested that memory consolidation from the hippocampus to the neocortex is facilitated by the activation synchronized with multiple exact or false replays of the encoded experience in the hippocampus. This implies that the hippocampus functions as a generative associative network.
<h2 id="2-contributions">
  2. Contributions
  <a class="anchor" href="#2-contributions">#</a>
</h2>
<ol>
<li>
<p>Larimar introduces a class of memory-conditioned language models inspired by complementary learning mechanisms in the brain. This architecture facilitates real-time test-time adaptation without requiring time-intensive gradient-based learning or internal fact tracing, offering a faster method for updating LLMs.
Utility Demonstration in Knowledge Editing and Context Generalization:</p>
</li>
<li>
<p>The proposed method is demonstrated on two significant and challenging use cases: knowledge editing and generalizing to longer input contexts. Larimar exhibits fast and accurate training-free adaptation to new inputs in both scenarios, outperforming baseline editing methods and existing language models.
Selective Fact Forgetting and Information Leakage Prevention:</p>
</li>
<li>
<p>Larimar effectively supports selective fact forgetting and prevents information leakage using its one-shot memory updating mechanism.
Recursive Search-Based Solution for Long Context Generalization: A simple recursive search-based approach is provided to enable Larimar&rsquo;s memory to generalize to longer input contexts.</p>
</li>
</ol>
<h2 id="3-model-architecture">
  3. Model architecture
  <a class="anchor" href="#3-model-architecture">#</a>
</h2>
<p>Larimar consists of three main components: encoder, decoder, and adaptive memory.</p>
<ol>
<li>Encoder: Transforms the input into a latent vector</li>
<li>Decoder: Generates an answer to the question conditioned on the memory</li>
<li>Memory: Stores episodes in encoded form</li>
</ol>
<p align="center">
    <img src='architecture.png' width="600">
</p>
<p align="center">
    (Fig7. Larimar architecture)
</p>
<h2 id="4-memory-operations">
  4. Memory Operations
  <a class="anchor" href="#4-memory-operations">#</a>
</h2>
<h2 id="5-results">
  5. Results
  <a class="anchor" href="#5-results">#</a>
</h2>
<h3 id="wall-clock-time">
  Wall Clock time
  <a class="anchor" href="#wall-clock-time">#</a>
</h3>
<p align="center">
    <img src='wall_clock_time _result.PNG' width="800">
</p>
<p align="center">
    (Fig8. Wall Clock Time result)
</p>
<h3 id="single-fact-editing">
  Single Fact Editing
  <a class="anchor" href="#single-fact-editing">#</a>
</h3>
<p align="center">
    <img src='Single_fact_editing_result.PNG' width="600">
</p>
<p align="center">
    (Fig9. )
</p>
<h3 id="sequential-fact-editing">
  Sequential Fact Editing
  <a class="anchor" href="#sequential-fact-editing">#</a>
</h3>
<p align="center">
    <img src='sequential_fact_editing_result.PNG' width="400">
</p>
<p align="center">
    (Fig10. Selective fact forgetting: LLMs should forget personal & sensitive data)
</p>
<h3 id="selective-forgetting">
  Selective Forgetting
  <a class="anchor" href="#selective-forgetting">#</a>
</h3>
<p align="center">
    <img src='memoryerase_result.PNG' width="500">
</p>
<p align="center">
    (Fig11. Selective fact forgetting: LLMs should forget personal & sensitive data)
</p>
<h3 id="recall-performance">
  Recall Performance
  <a class="anchor" href="#recall-performance">#</a>
</h3>
<p align="center">
    <img src='recall_performance_result.PNG' width="800">
</p>
<p align="center">
    (Fig12. Selective fact forgetting: LLMs should forget personal & sensitive data)
</p>
<h2 id="6-conclusion">
  6. Conclusion
  <a class="anchor" href="#6-conclusion">#</a>
</h2>
<h2 id="7-references">
  7. References
  <a class="anchor" href="#7-references">#</a>
</h2>
<p><a href="https://arxiv.org/abs/2310.16218">https://arxiv.org/abs/2310.16218</a>
-&gt; Knowledge Editing for Large Language Models: A Survey</p>
<p><a href="https://arxiv.org/abs/2207.04901">https://arxiv.org/abs/2207.04901</a>
-&gt; Exploring Length Generalization in Large Language Models</p>
<p><a href="https://arxiv.org/abs/2402.05813">https://arxiv.org/abs/2402.05813</a>
-&gt; Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models</p>
<p><a href="https://arxiv.org/abs/2403.11901">https://arxiv.org/abs/2403.11901</a></p>
<p><a href="https://www.rallyware.com/blog/the_neuroscience_behind_successful_talent_development">brain figure</a></p>
<p><a href="https://openreview.net/forum?id=Harn4_EZBw">https://openreview.net/forum?id=Harn4_EZBw</a>
-&gt; Generative Pseudo-Inverse Memory</p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">


  <div><a class="flex align-center" href="https://github.com/effml-postech/blog-post/commit/09d0440407f9953465e8c825cbdec2d13f3731c9" title='Last modified by skjang238 | May 20, 2024' target="_blank" rel="noopener">
      <img src="/svg/calendar.svg" class="book-icon" alt="" />
      <span>May 20, 2024</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/effml-postech/blog-post/edit/main//content/docs/spring24/22_/_index.md" target="_blank" rel="noopener">
      <img src="/svg/edit.svg" class="book-icon" alt="" />
      <span>Edit this page</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#1-background">1. Background</a>
      <ul>
        <li><a href="#knowledge-edit-in-llm-research">Knowledge edit in LLM research</a></li>
        <li><a href="#autoencoder">Autoencoder</a></li>
        <li><a href="#memory-network">Memory network</a></li>
        <li><a href="#neocortex-hippocampus-interactions">Neocortex-Hippocampus interactions</a></li>
      </ul>
    </li>
    <li><a href="#2-contributions">2. Contributions</a></li>
    <li><a href="#3-model-architecture">3. Model architecture</a></li>
    <li><a href="#4-memory-operations">4. Memory Operations</a></li>
    <li><a href="#5-results">5. Results</a>
      <ul>
        <li><a href="#wall-clock-time">Wall Clock time</a></li>
        <li><a href="#single-fact-editing">Single Fact Editing</a></li>
        <li><a href="#sequential-fact-editing">Sequential Fact Editing</a></li>
        <li><a href="#selective-forgetting">Selective Forgetting</a></li>
        <li><a href="#recall-performance">Recall Performance</a></li>
      </ul>
    </li>
    <li><a href="#6-conclusion">6. Conclusion</a></li>
    <li><a href="#7-references">7. References</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












