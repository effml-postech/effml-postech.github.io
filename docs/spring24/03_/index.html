<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Unit Scaling # Unit scaling is proposed to address the limitations of existing methods for managing scale in typical models. A model is considered unit-scaled if its activations, weights, and gradients have approximately unit variance at initialization. This is achieved by inserting scaling factors into the forward and backward passes. Unlike loss scaling, which requires an empirically determined hyperparameter or an adaptive algorithm, unit scaling determines these scales based on a set of rules for each operation, approximately preserving the variance of the inputs.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/docs/spring24/03_/">
  <meta property="og:site_name" content="Efficient ML Systems">
  <meta property="og:title" content="Efficient ML Systems">
  <meta property="og:description" content="Unit Scaling # Unit scaling is proposed to address the limitations of existing methods for managing scale in typical models. A model is considered unit-scaled if its activations, weights, and gradients have approximately unit variance at initialization. This is achieved by inserting scaling factors into the forward and backward passes. Unlike loss scaling, which requires an empirically determined hyperparameter or an adaptive algorithm, unit scaling determines these scales based on a set of rules for each operation, approximately preserving the variance of the inputs.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="website">
<title>03 | Efficient ML Systems</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" >
<link rel="canonical" href="http://localhost:1313/docs/spring24/03_/">
<link rel="stylesheet" href="/book.min.309b7ed028807cdb68d8d61e26d609f48369c098dbf5e4d8c0dcf4cdf49feafc.css" integrity="sha256-MJt&#43;0CiAfNto2NYeJtYJ9INpwJjb9eTYwNz0zfSf6vw=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.c6e5f64589a55dcb16209f6b6cf56c358b32499975ba19ce4d0e7bcaf6b71192.js" integrity="sha256-xuX2RYmlXcsWIJ9rbPVsNYsySZl1uhnOTQ57yva3EZI=" crossorigin="anonymous"></script>

  

<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/docs/spring24/03_/index.xml" title="Efficient ML Systems" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>Efficient ML Systems</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8c2bdf4d8f82cc2d8f16541464d61b3d" class="toggle" checked />
    <label for="section-8c2bdf4d8f82cc2d8f16541464d61b3d" class="flex justify-between">
      <a role="button" class="">Spring24</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/00_taco_example/" class="">00 Taco Example</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/01_/" class="">01</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/02_/" class="">02</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/03_/" class="active">03</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/04_/" class="">04</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/05_/" class="">05</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/06_/" class="">06</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/07_/" class="">07</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/08_/" class="">08</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/09_/" class="">09</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/10_/" class="">10</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/11_/" class="">11</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/12_/" class="">12</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/13_/" class="">13</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/14_/" class="">14</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/15_/" class="">15</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/16_/" class="">16</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/17_/" class="">17</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/18_/" class="">18</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/19_/" class="">19</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/20_/" class="">20</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/21_/" class="">21</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/22_/" class="">22</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/23_/" class="">23</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/24_/" class="">24</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/spring24/25_/" class="">25</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>03</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#unit-scaling">Unit Scaling</a>
      <ul>
        <li><a href="#a-framework-for-scaling-computational-graphs">A framework for scaling computational graphs</a></li>
        <li><a href="#a-scaling-strategy-for-unit-variance">A scaling strategy for unit variance</a></li>
        <li><a href="#weighted-addition">Weighted addition</a></li>
        <li><a href="#recipe">Recipe</a></li>
        <li><a href="#example">Example</a></li>
      </ul>
    </li>
    <li><a href="#results">Results</a></li>
    <li><a href="#related-work">Related Work</a></li>
    <li><a href="#discussion">Discussion</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h2 id="unit-scaling">
  Unit Scaling
  <a class="anchor" href="#unit-scaling">#</a>
</h2>
<p>Unit scaling is proposed to address the limitations of existing methods for managing scale in typical models. A model is considered unit-scaled if its activations, weights, and gradients have approximately unit variance at initialization. This is achieved by inserting scaling factors into the forward and backward passes. Unlike loss scaling, which requires an empirically determined hyperparameter or an adaptive algorithm, unit scaling determines these scales based on a set of rules for each operation, approximately preserving the variance of the inputs. This leads to global unit scaling throughout the model, ensuring tensor values are centered within the exponent range at initialization, providing headroom during training to avoid going out of range.</p>
<h3 id="a-framework-for-scaling-computational-graphs">
  A framework for scaling computational graphs
  <a class="anchor" href="#a-framework-for-scaling-computational-graphs">#</a>
</h3>
<ul>
<li>
<p>Computational Graphs</p>
<ul>
<li>Represent model by the differentiable function 
<link rel="stylesheet" href="/katex/katex.min.css" />
<script defer src="/katex/katex.min.js"></script>
<script defer src="/katex/auto-render.min.js" onload="renderMathInElement(document.body);"></script><span>
  \(f_{model}(x_1,...,x_m)\)
</span>
</li>
<li>Describe the structure of such a model using a directed acyclic graph (DAG) denoted <span>
  \(\mathcal{G} =(\mathcal{V}, \mathcal{E}) \)
</span>
</li>
<li>This kind of graph is commonly known as a <em>computational graph</em>, with vertices as <em>nodes</em> and their corresponding functions
as <em>ops</em>.</li>
</ul>
</li>
<li>
<p>Forward and backward graphs</p>
<ul>
<li>We refer to the computational graph corresponding to <span>
  \(f_{model}\)
</span>
 as the <strong>forward graph</strong></li>
<li>In deep learning we typically apply reverse-mode automatic differentiation to the forward graph to create a second computational graph whose output nodes represent the partial derivatives of the model with respect to its inputs: <span>
  \( \frac{\partial f_{model}}{\partial x_i}, \forall i \in[1 . . m] \)
</span>
. We call this the <em>backward graph</em></li>
</ul>
</li>
<li>
<p>Scaled ops</p>
<ul>
<li>Given an op <span>
  \(f\left(x_1, \ldots, x_k\right)\)
</span>
, we define the <em>scaled op</em> <span>
  \( f^*\left(x_1, \ldots, x_k, \alpha, \beta_1, \ldots, \beta_k\right) \)
</span>
 with <em>scaling factors</em> <span>
  \( \alpha, \beta_1, \ldots, \beta_k \in \mathbb{R}^{&#43;} \)
</span>
, such that</li>
</ul>
</li>
</ul>
<span>
  \(f^* &amp; \triangleq \alpha \cdot f\left(x_1, \ldots, x_k\right)\)
</span>

<span>
  \( f_{\text {grad }}^*\left(x_1, \ldots x_k, g\right)_i &amp; \triangleq \beta_i \cdot f_{\text {grad }}\left(x_1, \ldots x_k, g\right)_i, \forall i \in[1 . . k] \)
</span>

<ul>
<li>
<p>Scaled computational graph</p>
<ul>
<li>A scaled computational graph is one where every op <span>
  \(f\)
</span>
 in the forward graph is replaced by a scaled equivalent <span>
  \(f^{*}\)
</span>
, with the backward graph then generated to produce <span>
  \(f^{*}_{grad}\)
</span>
 grad for each <span>
  \(f_{grad}\)
</span>
, using any choice of scaling factors.</li>
</ul>
</li>
<li>
<p>Constraint-scaled computational graphs</p>
<ul>
<li>A constraint-scaled computational graph is a scaled computational graph where we restrict the scaling factors of ops that consume non-cut-edge variables in the following way: for any edge <span>
  \(e \notin \mathcal{C}\)
</span>
, we require the op consuming the variable <span>
  \(x_e\)
</span>
 to have scaling factors <span>
  \(\alpha = \beta_e f\)
</span>
.</li>
</ul>
</li>
</ul>
<p><strong>Proposition 5.1</strong></p>
<p><em>For any scaled op, there is an equivalent unscaled op with the same training dynamics under a firstorder optimiser.</em></p>
<p><strong>Theorem 5.2</strong></p>
<p><em>A constraint-scaled computational graph itself represents a scaled op.</em></p>
<h3 id="a-scaling-strategy-for-unit-variance">
  A scaling strategy for unit variance
  <a class="anchor" href="#a-scaling-strategy-for-unit-variance">#</a>
</h3>
<ul>
<li>
<p>Unit scaled computational graphs</p>
<ul>
<li>Initially set aside any scale constraints, and calculate the scaling factors that give each op expected unit variance outputs (this process is covered below).</li>
<li>Now resolve any scale constraints by taking each constrained group <span>
  \( {\alpha, \beta_1, \ldots, \beta_l } \)
</span>
 and selecting the geometric mean <span>
  \( \left(\alpha, \beta_1, \ldots, \beta_l \right)^\frac{1}{l&#43;1} \)
</span>
</li>
</ul>
</li>
<li>
<p>Selecting scaling factors</p>
<ul>
<li>Assuming unit-scaled inputs to <span>
  \( y = f(x_i,\ldots,x_k) \)
</span>
, derive the output scale <span>
  \( \sigma_Y \)
</span>
 and set the forward scaling factor <span>
  \( \alpha = 1/\sigma_Y \)
</span>
 . Repeat this process for <span>
  \( x_i&#39;=f_{grad}(\ldots)_i, \forall i \in[1 . . k] \)
</span>
, to obtain the gradient scale <span>
  \( \sigma_{x_i&#39;} \)
</span>
 i and set the backward scaling factor <span>
  \( \beta_i = 1/\sigma_{x_i&#39;} \)
</span>
 .</li>
</ul>
</li>
</ul>
<h3 id="weighted-addition">
  Weighted addition
  <a class="anchor" href="#weighted-addition">#</a>
</h3>
<p>When tensors of different scales, such as those in residual layers, losses, and positional encodings, are added, simply adding them can adversely affect performance. To address this, we propose using weighted_add. In this approach, we can maintain unit scale while performing operations using a scaled identity function.</p>
<h3 id="recipe">
  Recipe
  <a class="anchor" href="#recipe">#</a>
</h3>
<p>We now outline a high-level recipe for a unit-scaled model:</p>
<ol>
<li>Initialise non-bias parameters with unit variance.</li>
<li>Calculate scaling factors for all scaled ops.</li>
<li>Identify non-cut-edges, and constrain the ops consumingthem to have <span>
  \( \alpha = \beta \)
</span>
 by taking the geometric mean.</li>
<li>Replace adds with weighted adds.</li>
</ol>
<h3 id="example">
  Example
  <a class="anchor" href="#example">#</a>
</h3>
<p>Using the unit scaling recipe, we first build a scaled op, and then a full scaled layer. Consider a scaled projection op with learnable weights:</p>
<p align="center">
    <span>
  \( \operatorname{matmul}^*(X,W) =\alpha \cdot X W \)
</span>
 
</p>
<p align="center">
    <span>
  \( \operatorname{matmul}_{\text {grad }}^*(X, W, G)_1 = \beta_1 \cdot G W^{\top} \)
</span>
   
</p>   
<p align="center">
    <span>
  \( \operatorname{matmul}_{\text {grad }}^*(X, W, G)_2 = \beta_2 \cdot X^{\top} G \)
</span>

</p>  
<p>for input <span>
  \( X \in \mathbb{R}^{b \times m}  \)
</span>
, weight  <span>
  \( W \in \mathbb{R}^{m \times n} \)
</span>
, output <span>
  \( \mathbb{R}^{b \times n} \)
</span>
 and incoming gradients <span>
  \( G \in \mathbb{R}^{b \times n} \)
</span>
</p>
<p>We show code for the above in Figure 3, which also gives a scaled layer for the Transformer FFN</p>
<p align="center">
    <img src='./Figure3.PNG' width="900">
</p>
<p align="center">
    Fig3. PyTorch examples
</p>
<h2 id="results">
  Results
  <a class="anchor" href="#results">#</a>
</h2>
<ul>
<li>
<p>Character language modelling</p>
<ul>
<li>
<p>Experimental Setup: Train causal language models on WikiText-103 raw character language modeling, using cross-entropy loss during training and evaluating on bits per character (BPC). Below the product of these settings, we compare the performance of regular (baseline) and unit scaling in both FP32 and FP16.</p>
<ul>
<li><em>Sequence layer type</em>: Attention, RNN and Convolution</li>
<li><em>Norm placement</em>: PreNorm, PostNorm and NoNorm</li>
<li><em>Residual scaling</em>: default, fixed and running-mean</li>
</ul>
</li>
<li>
<p>Results</p>
<ul>
<li>First, these demonstrate the need for scaling when using FP16. This is due to gradient underflow, since loss scaling with a factor of 2048 resolves the issue.</li>
<li>Second, they demonstrate that unit scaling, despite changing the training behaviour of the model beyond just numerics, matches or even slightly improves upon baseline performance in almost all cases.</li>
<li>Finally, they show that no tuning is necessary when switching unit scaling to FP16.</li>
<li>suggest that running-mean or fixed are reasonable choices when using unit scaling</li>
</ul>
</li>
</ul>
</li>
</ul>
<p align="center">
    <img src='./Figure4.png' width="400">
</p>
<p align="center">
    Fig4. Character language modelling, showing validation bits per character over a wide range of models
</p>
<ul>
<li>
<p>Masked language modelling</p>
<ul>
<li>
<p>Experimental Setup</p>
<ul>
<li>To evaluate the advantages of unit scaling, we assess BERTBASE and BERTLARGE models, which typically struggle with loss scaling.</li>
</ul>
</li>
<li>
<p>Results</p>
</li>
</ul>
</li>
</ul>
<p align="center">
    <img src='./Table2.PNG' width="800">
</p>
<p align="center">
    Table2. Downstream performance of regular and unit-scaled BERT models
</p>
<h2 id="related-work">
  Related Work
  <a class="anchor" href="#related-work">#</a>
</h2>
<p><strong>Variance scaling analysis</strong></p>
<p><strong>FP8 inference</strong></p>
<h2 id="discussion">
  Discussion
  <a class="anchor" href="#discussion">#</a>
</h2>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">


  <div><a class="flex align-center" href="https://github.com/effml-postech/blog-post/commit/b5c69a8d6fa11560475531403f85e1e4dc46708b" title='Last modified by effml-postech | May 20, 2024' target="_blank" rel="noopener">
      <img src="/svg/calendar.svg" class="book-icon" alt="" />
      <span>May 20, 2024</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/effml-postech/blog-post/edit/main//content/docs/spring24/03_/_index.md" target="_blank" rel="noopener">
      <img src="/svg/edit.svg" class="book-icon" alt="" />
      <span>Edit this page</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#unit-scaling">Unit Scaling</a>
      <ul>
        <li><a href="#a-framework-for-scaling-computational-graphs">A framework for scaling computational graphs</a></li>
        <li><a href="#a-scaling-strategy-for-unit-variance">A scaling strategy for unit variance</a></li>
        <li><a href="#weighted-addition">Weighted addition</a></li>
        <li><a href="#recipe">Recipe</a></li>
        <li><a href="#example">Example</a></li>
      </ul>
    </li>
    <li><a href="#results">Results</a></li>
    <li><a href="#related-work">Related Work</a></li>
    <li><a href="#discussion">Discussion</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












